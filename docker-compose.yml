version: '3'

services:
  hadoop-master:
    build:
      context: .
      dockerfile: docker/hadoop-master/Dockerfile
    container_name: hadoop-master
    hostname: hadoop-master
    ports:
      - "9870:9870"  # Hadoop NameNode web UI
      - "8088:8088"  # ResourceManager web UI
    volumes:
      - hadoop_namenode:/opt/hadoop/dfs/name
    environment:
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - hadoop_network

  hadoop-worker1:
    build:
      context: .
      dockerfile: docker/hadoop-worker/Dockerfile
    container_name: hadoop-worker1
    hostname: hadoop-worker1
    volumes:
      - hadoop_datanode1:/opt/hadoop/dfs/data
      - ./src:/app/src
      - ./requirements.txt:/app/requirements.txt
    environment:
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    depends_on:
      - hadoop-master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9864"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - hadoop_network

  hadoop-worker2:
    build:
      context: .
      dockerfile: docker/hadoop-worker/Dockerfile
    container_name: hadoop-worker2
    hostname: hadoop-worker2
    volumes:
      - hadoop_datanode2:/opt/hadoop/dfs/data
      - ./src:/app/src
      - ./requirements.txt:/app/requirements.txt
    environment:
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    depends_on:
      - hadoop-master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9864"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - hadoop_network

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/opt/zookeeper-3.4.13/data
    networks:
      - hadoop_network

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "reddit_posts:1:1"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - kafka_data:/kafka
    depends_on:
      - zookeeper
    networks:
      - hadoop_network

  hbase:
    image: harisekhon/hbase
    container_name: hbase
    ports:
      - "16010:16010"
    environment:
      HBASE_MANAGES_ZK: "false"
      HBASE_ZOOKEEPER_QUORUM: zookeeper
    volumes:
      - hbase_data:/hbase-data
    depends_on:
      - hadoop-master
      - zookeeper
    networks:
      - hadoop_network

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - spark_master_data:/bitnami/spark
    networks:
      - hadoop_network

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - spark_worker_data:/bitnami/spark
    depends_on:
      - spark-master
    networks:
      - hadoop_network

volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  zookeeper_data:
  kafka_data:
  hbase_data:
  spark_master_data:
  spark_worker_data:

networks:
  hadoop_network:
    driver: bridge